{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import branch_length\n",
    "import distributions\n",
    "import optimizers\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "alt.renderers.enable(\"notebook\")\n",
    "\n",
    "import importlib \n",
    "importlib.reload(branch_length)\n",
    "importlib.reload(distributions)\n",
    "importlib.reload(optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(0.1, 5, 40)\n",
    "x_vals_transpose = np.transpose(np.array([x_vals]))\n",
    "\n",
    "def plot_functions(f_true, f_approx):\n",
    "    x_transpose = np.transpose(np.array([x_vals]))\n",
    "    data = pd.DataFrame({\"x\": x_vals, \"truth\": f_true(x_vals_transpose), \n",
    "                         \"approx\": f_approx(x_vals_transpose)})\n",
    "    return alt.Chart(data.melt(id_vars=[\"x\"])).mark_line().encode(\n",
    "        x='x',\n",
    "        y='value',\n",
    "        color='variable'\n",
    "    )\n",
    "\n",
    "def kl_div(f_true, f_approx):\n",
    "    return {\n",
    "        \"standard\": stats.entropy(f_true(x_vals_transpose), f_approx(x_vals_transpose)),\n",
    "        \"reversed\": stats.entropy(f_approx(x_vals_transpose), f_true(x_vals_transpose))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_length_param_count = 1\n",
    "infer_opt = optimizers.SGD_Server(\n",
    "    {'loc': branch_length_param_count, 'shape': branch_length_param_count})\n",
    "stepsz = 0.05\n",
    "stepsz_dict = {'loc': stepsz, 'shape': stepsz}\n",
    "\n",
    "# Distribution we wish to approximate-- we pretend this is the \"phylogenetic\" distribution.\n",
    "d = distributions.Normal(1)\n",
    "true_loc = np.array([4.])\n",
    "true_shape = np.array([1.])\n",
    "phylo_log_like = lambda x: d.log_prob(x, true_loc, true_shape)\n",
    "phylo_log_like_grad = lambda x: d.log_prob_grad(x, true_loc, true_shape)\n",
    "\n",
    "# Variational distribution\n",
    "q = distributions.Normal(1)\n",
    "loc = np.array([1.])\n",
    "shape = np.array([0.5])\n",
    "q_log_like = lambda x: q.log_prob(x, loc, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(sample_count):\n",
    "    global loc, shape\n",
    "    x = q.sample(loc, shape, sample_count)\n",
    "    weights = branch_length.like_weights(q, phylo_log_like(x), x, loc, shape)\n",
    "    loc_grad, shape_grad = branch_length.param_grad(q, weights, phylo_log_like_grad(x), x, loc, shape)\n",
    "    update_dict = infer_opt.adam(stepsz_dict, {'loc': loc, 'shape': shape}, \n",
    "                                 {'loc': loc_grad, 'shape': shape_grad})\n",
    "    loc += update_dict['loc']\n",
    "    shape += update_dict['shape']\n",
    "    return kl_div(phylo_log_like, q_log_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = np.array([0.5])\n",
    "shape = np.array([1.])\n",
    "results = [kl_div(phylo_log_like, q_log_like)]\n",
    "\n",
    "for _ in range(200):\n",
    "    results.append(gradient_step(10))\n",
    "\n",
    "plot_data = pd.DataFrame(results).reset_index()\n",
    "    \n",
    "alt.Chart(\n",
    "    pd.melt(plot_data, id_vars=[\"index\"], var_name=\"variant\", value_name=\"KL divergence\")\n",
    "    ).mark_line().encode(\n",
    "        alt.X(\"index\"),\n",
    "        alt.Y(\"KL divergence\",\n",
    "              scale=alt.Scale()),\n",
    "        color=\"variant\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_step(10)\n",
    "plot_functions(phylo_log_like, q_log_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_functions(phylo_log_like, q_log_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = q.sample(loc, shape, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = branch_length.like_weights(q, phylo_log_like(x), x, loc, shape)\n",
    "print(\"weighted:\\t\", branch_length.param_grad(q, weights, phylo_log_like_grad(x), x, loc, shape))\n",
    "uniform_weights = np.ones(weights.shape) / len(weights)\n",
    "print(\"unweighted:\\t\", branch_length.param_grad(q, uniform_weights, phylo_log_like_grad(x), x, loc, shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_grad, shape_grad = param_grad_gory(q, weights, phylo_log_like_grad(x), x, loc, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_simple = x.transpose()[0]\n",
    "df = pd.DataFrame(\n",
    "    {\"x\": x_simple, \"epsilon\": (x_simple - loc)/shape, \"weights\": weights, \n",
    "     \"loc_grad\": loc_grad.transpose()[0], \"shape_grad\": shape_grad.transpose()[0]})\n",
    "df.sort_values(\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((x, shape_grad), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def param_grad_gory(q_distribution, weights, phylo_gradient, x, loc, shape):\n",
    "    \"\"\"The gradient with respect to the parameters of the variational\n",
    "    distribution using the reparametrization trick.\n",
    "\n",
    "    See (7) of the 2018 ICLR paper.\n",
    "    \"\"\"\n",
    "    # Recall that the branch lengths are parameterized in terms of the variational\n",
    "    # parameters (epsilon is considered fixed) so when we take their derivative we need\n",
    "    # to take the branch length derivative:\n",
    "    d_log_prob_ratio = phylo_gradient - q_distribution.log_prob_grad(x, loc, shape)\n",
    "    # ... and then the reparametrization derivative due to the chain rule.\n",
    "    d_reparam_loc, d_reparam_shape = q_distribution.reparam_grad(x, loc, shape)\n",
    "    # This is the derivative with respect to the variational parametrization itself.\n",
    "    d_q_loc, d_q_shape = q_distribution.log_prob_param_grad(x, loc, shape)\n",
    "    # Here are the full derivatives, where the first term is the derivative WRT\n",
    "    # parameters in the reparameterization trick and the second is WRT the actual\n",
    "    # variational parameterization.\n",
    "    d_loc = d_log_prob_ratio * d_reparam_loc - d_q_loc\n",
    "    d_shape = d_log_prob_ratio * d_reparam_shape - d_q_shape\n",
    "    # Our multiple samples are laid out on axis 0, so this multiplication on the left\n",
    "    # reweights them.\n",
    "    #weights = np.ones(weights.shape)/len(weights)\n",
    "    return d_loc, d_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = q.sample(loc, shape, 100)\n",
    "weights = branch_length.like_weights(q, phylo_log_like(x), x, loc, shape)\n",
    "branch_length.param_grad(q, weights, phylo_log_like_grad(x), x, loc, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"x\": x[:,0], \"weights\": weights})\n",
    "df.sort_values(\"x\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_line().encode(\n",
    "        alt.X(\"x\"),\n",
    "        alt.Y(\"weights\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
